name: Automated Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  
  # Allow manual trigger
  workflow_dispatch:

jobs:
  backup:
    name: Backup Production Database
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Create backup
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
          BACKUP_FILE="viz_backup_${TIMESTAMP}.sql"
          
          mkdir -p backups
          pg_dump "$DATABASE_URL" > "backups/$BACKUP_FILE"
          gzip "backups/$BACKUP_FILE"
          
          echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV

      - name: Upload backup artifact
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-${{ env.BACKUP_FILE }}
          path: backups/${{ env.BACKUP_FILE }}
          retention-days: 30

      - name: Upload to S3 (Optional)
        if: ${{ secrets.AWS_S3_BUCKET != '' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          aws s3 cp "backups/${{ env.BACKUP_FILE }}" \
            "s3://$AWS_S3_BUCKET/backups/${{ env.BACKUP_FILE }}"

      - name: Notify on success
        if: success()
        run: echo "✅ Database backup completed successfully"

      - name: Notify on failure
        if: failure()
        run: |
          echo "❌ Database backup failed!"
          # Add notification logic here (Slack, Discord, etc.)
